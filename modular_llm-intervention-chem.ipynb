{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, get_scheduler\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import plotly.express as px\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/nas/ucb/satvik/hf_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/gemma-1.1-2b-it\" # Using 2b version for potentially faster loading/iteration\n",
    "DATASET_NAME = \"XythicK/Chemistry\"\n",
    "DATASET_CONFIG = None  # Chemistry dataset doesn't have a config\n",
    "# Using a very small slice for quick testing/demonstration\n",
    "DATASET_SLICE_TRAIN = \"train[:180]\"\n",
    "DATASET_SLICE_TEST = \"train[180:420]\"  # Held-out set from Chemistry dataset\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 2 # Keep small for memory constraints\n",
    "MAX_SEQ_LENGTH = 256 # Reduce sequence length for memory\n",
    "LEARNING_RATE = 1e-5 # Adjusted learning rate\n",
    "LOSS_FILE = \"train_losses.txt\"\n",
    "TARGET_LAYER_INDEX = -2 # Second to last layer\n",
    "MLORA_RANK = 256 # Rank for MLoRA matrices\n",
    "CLUSTERABILITY_WEIGHT = 10.0 # Weight for clusterability term in loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \"\"\"Load environment variables and set device.\"\"\"\n",
    "    load_dotenv()\n",
    "    # hf_token = os.getenv(\"HF_TOKEN\")\n",
    "    hf_token = \"\"\n",
    "    if not hf_token:\n",
    "        logging.warning(\"HF_TOKEN environment variable not found. Ensure you are logged in via huggingface-cli login or set the HF_TOKEN.\")\n",
    "    # Use HF_TOKEN if available (required for Gemma models)\n",
    "    # Note: transformers automatically uses HF_TOKEN env var if present\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLoRAAdapter(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, rank=8):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.rank = rank\n",
    "        \n",
    "        logging.info(f\"Initializing MLoRA with dims: input={input_dim}, output={output_dim}, rank={rank}\")\n",
    "        \n",
    "        # MLoRA matrices\n",
    "        self.A = nn.Linear(input_dim, rank, bias=False)\n",
    "        self.B = nn.Linear(rank, rank, bias=False)\n",
    "        self.C = nn.Linear(rank, output_dim, bias=False)\n",
    "        \n",
    "        # Initialize with small values\n",
    "        nn.init.normal_(self.A.weight, std=0.01)\n",
    "        nn.init.normal_(self.B.weight, std=0.01)\n",
    "        nn.init.normal_(self.C.weight, std=0.01)\n",
    "        \n",
    "        # Scale factor to prevent output from dominating the residual\n",
    "        self.scaling = 0.1\n",
    "        \n",
    "        # ReLU activations for H1 and H2\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Log shape for debugging\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1) if x.dim() > 2 else 1\n",
    "        \n",
    "        # Reshape if needed to handle different input formats\n",
    "        if x.dim() > 2:\n",
    "            # If x is [batch_size, seq_len, hidden_dim]\n",
    "            orig_shape = x.shape\n",
    "            x_reshaped = x.view(-1, self.input_dim)\n",
    "        else:\n",
    "            # If x is already [batch_size, hidden_dim]\n",
    "            x_reshaped = x\n",
    "            \n",
    "        # MLoRA forward pass: x -> A -> H1 -> B -> H2 -> C -> out\n",
    "        h1 = self.activation(self.A(x_reshaped))\n",
    "        h2 = self.activation(self.B(h1))\n",
    "        out = self.C(h2)\n",
    "        \n",
    "        # Apply scaling\n",
    "        out = out * self.scaling\n",
    "        \n",
    "        # Reshape back to original shape if needed\n",
    "        if x.dim() > 2:\n",
    "            out = out.view(orig_shape)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def get_B_matrix(self):\n",
    "        # Return B matrix for clusterability computation\n",
    "        return self.B.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemistryDataset(Dataset):\n",
    "    def __init__(self, texts, topics, subtopics, tokenizer, max_length):\n",
    "\n",
    "        assert len(texts) == len(topics) == len(subtopics), \"Texts, topics, and subtopics must have the same length.\"\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.encodings = []\n",
    "        \n",
    "        logging.info(\"Tokenizing dataset...\")\n",
    "        skipped_count = 0\n",
    "        \n",
    "        for i, text in enumerate(tqdm(texts, desc=\"Tokenizing\")):\n",
    "            # Basic check for valid text (ensure it's a string and not too short)\n",
    "            if text and isinstance(text, str) and len(text.strip()) > 10:\n",
    "                try:\n",
    "                    # Tokenize, pad, and truncate\n",
    "                    tokenized = tokenizer(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        max_length=self.max_length,\n",
    "                        padding=\"max_length\",\n",
    "                        return_tensors=\"pt\",\n",
    "                    )\n",
    "                    # Remove the batch dimension added by the tokenizer\n",
    "                    input_ids = tokenized[\"input_ids\"].squeeze(0)\n",
    "                    attention_mask = tokenized[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "                    # Create labels by cloning input_ids\n",
    "                    # For Causal LM, labels are typically input_ids.\n",
    "                    # Padding token ids in labels are replaced with -100 to be ignored in loss calculation.\n",
    "                    labels = input_ids.clone()\n",
    "                    labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "                    self.encodings.append({\n",
    "                        \"input_ids\": input_ids,\n",
    "                        \"attention_mask\": attention_mask,\n",
    "                        \"labels\": labels,\n",
    "                        \"topic\": topics[i],\n",
    "                        \"subtopic\": subtopics[i]\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Skipping text due to tokenization error: {e}. Text snippet: {text[:100]}...\")\n",
    "                    skipped_count += 1\n",
    "            else:\n",
    "                # Log or count texts that are None, not strings, or too short\n",
    "                if not (text and isinstance(text, str)):\n",
    "                    logging.debug(f\"Skipping non-string or empty text entry: {type(text)}\")\n",
    "                elif len(text.strip()) <= 10:\n",
    "                    logging.debug(f\"Skipping short text entry: {text[:30]}...\")\n",
    "                skipped_count += 1\n",
    "\n",
    "        if skipped_count > 0:\n",
    "            logging.warning(f\"Skipped {skipped_count} invalid or short text entries.\")\n",
    "        if not self.encodings:\n",
    "            raise ValueError(\"No valid data processed. Check dataset content, filtering, and 'TEXT' field extraction.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the dictionary directly, DataLoader will batch items\n",
    "        return self.encodings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hf = load_dataset(\n",
    "    DATASET_NAME,\n",
    "    None,\n",
    "    split='train[180:2000]', \n",
    "    trust_remote_code=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Inorganic Chemistry', 'Organic Chemistry', 'Physical Chemistry'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data_hf['Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alkenes', 'Kinetics', 'Nomenclature', 'Oxidation States'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data_hf['Subtopic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(tokenizer, dataset_slice, dataset_name_arg, dataset_config_arg, max_seq_length_arg, batch_size_arg):\n",
    "    \"\"\"Loads and preprocesses the dataset.\"\"\"\n",
    "    logging.info(f\"Loading dataset: {dataset_name_arg}, Config: {dataset_config_arg}, Slice: {dataset_slice}...\")\n",
    "    try:\n",
    "        # Use arguments for dataset name and config\n",
    "        data_hf = load_dataset(dataset_name_arg, dataset_config_arg, split=dataset_slice, trust_remote_code=True)\n",
    "\n",
    "        # Extract text data - ensure we get strings from the 'TEXT' field for the chemistry dataset\n",
    "        # Also handle cases where 'TEXT' might be missing or not a string for robustness\n",
    "        texts = []\n",
    "        topics = []\n",
    "        subtopics = []\n",
    "        for item in data_hf:\n",
    "            question_content = item.get('Question')\n",
    "            answer_content = item.get(\"Answer_1\")\n",
    "            topic = item.get(\"Topic\")\n",
    "            subtopic = item.get(\"Subtopic\")\n",
    "            text_content = f\"<start_of_turn>user\\n{question_content}<end_of_turn>\\n<start_of_turn>model\\n{answer_content}<end_of_turn>\"\n",
    "            # text_content = question_content + answer_content\n",
    "            if isinstance(text_content, str):\n",
    "                texts.append(text_content)\n",
    "                topics.append(topic)\n",
    "                subtopics.append(subtopic)\n",
    "            else:\n",
    "                logging.debug(f\"Found item without valid 'TEXT' field or non-string content: {item}\")\n",
    "\n",
    "        logging.info(f\"Loaded {len(texts)} text documents from 'TEXT' field.\")\n",
    "        if not texts:\n",
    "            raise ValueError(\"No text data found in the 'TEXT' field of the dataset slice.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load or process dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Use argument for max_seq_length\n",
    "    dataset = ChemistryDataset(texts, topics, subtopics, tokenizer, max_seq_length_arg)\n",
    "    if len(dataset) == 0:\n",
    "        raise ValueError(\"Dataset created, but contains no processable entries. Check data and tokenization.\")\n",
    "\n",
    "    # Shuffle training data, don't shuffle test data\n",
    "    # This logic assumes specific slice names for train/test.\n",
    "    # Consider a more robust way if slice names vary (e.g., pass a boolean is_train flag).\n",
    "    is_train = \"train[\" in dataset_slice and \":180]\" in dataset_slice # Based on your example slice\n",
    "    # is_train = \"train\" in dataset_slice.lower() # A more general check\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size_arg, shuffle=is_train) # Use argument for batch_size\n",
    "    logging.info(f\"Created DataLoader with {len(dataloader)} batches.\")\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer():\n",
    "    \"\"\"Loads the model and tokenizer.\"\"\"\n",
    "    hf_token = \"\"\n",
    "    logging.info(f\"Loading tokenizer: {MODEL_NAME}\")\n",
    "    # trust_remote_code=True might be needed for some models\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True, token = hf_token)\n",
    "\n",
    "    # Set pad token if missing\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        logging.info(\"Set pad_token to eos_token\")\n",
    "\n",
    "    logging.info(f\"Loading model: {MODEL_NAME}\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        trust_remote_code=True,\n",
    "        token = hf_token,\n",
    "        cache_dir=\"/nas/ucb/satvik/hf_cache\",\n",
    "        # Use torch_dtype=torch.float16 or bfloat16 for memory efficiency if GPU supports it\n",
    "        # torch_dtype=torch.bfloat16,\n",
    "        # device_map=\"auto\" # Can help distribute large models across GPUs/CPU\n",
    "    )\n",
    "    # Ensure model's pad token id matches tokenizer's\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward_with_mlora(model, mlora_adapter, input_ids, attention_mask, labels=None):\n",
    "    \"\"\"\n",
    "    Custom forward pass that applies MLoRA adapter to the target MLP's output.\n",
    "    \"\"\"\n",
    "    # Prepare inputs\n",
    "    model_inputs = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }\n",
    "    \n",
    "    # If labels provided, add them to inputs\n",
    "    if labels is not None:\n",
    "        model_inputs[\"labels\"] = labels\n",
    "    \n",
    "    # Get original outputs - we need to handle the hidden states\n",
    "    model_inputs[\"output_hidden_states\"] = True\n",
    "    outputs = model(**model_inputs)\n",
    "    \n",
    "    # We need to modify this to return modified logits\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_mlora_hook(model, mlora_adapter, target_layer_index):\n",
    "    \"\"\"\n",
    "    Registers a forward hook on the target MLP layer to apply MLoRA.\n",
    "    \"\"\"\n",
    "    # For Gemma, the path to the MLP output is model.model.layers[index].mlp\n",
    "    target_layer = model.model.layers[target_layer_index].mlp\n",
    "    \n",
    "    # Get shape information for debugging\n",
    "    logging.info(f\"Registering hook on layer: {target_layer}\")\n",
    "    \n",
    "    # We need to track whether this is the first forward pass to log dimension info\n",
    "    first_pass = [True]\n",
    "    \n",
    "    def mlora_hook(module, input, output):\n",
    "        \"\"\"\n",
    "        Hook that applies MLoRA to the MLP output.\n",
    "        - input: tuple containing tensor of shape [batch_size, seq_len, hidden_dim]\n",
    "        - output: tensor of shape [batch_size, seq_len, hidden_dim]\n",
    "        \"\"\"\n",
    "        if first_pass[0]:\n",
    "            logging.info(f\"Hook input shape: {input[0].shape}\")\n",
    "            logging.info(f\"Hook output shape: {output.shape}\")\n",
    "            first_pass[0] = False\n",
    "        \n",
    "        try:\n",
    "            # Apply MLoRA adapter to the input tensor\n",
    "            mlora_output = mlora_adapter(input[0])\n",
    "            \n",
    "            # Handle shape mismatch if needed\n",
    "            if mlora_output.shape != output.shape:\n",
    "                logging.warning(f\"Shape mismatch: MLoRA output {mlora_output.shape}, MLP output {output.shape}\")\n",
    "                # Reshape to match output dimensions\n",
    "                mlora_output = mlora_output.view_as(output)\n",
    "            \n",
    "            # Add residual connection\n",
    "            return output + mlora_output\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            # If there's an error, log it but return the original output to prevent training failure\n",
    "            logging.error(f\"Error in MLoRA hook: {e}\")\n",
    "            return output\n",
    "    \n",
    "    # Register the hook to run after the MLP forward pass\n",
    "    hook_handle = target_layer.register_forward_hook(mlora_hook)\n",
    "    return hook_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, mlora_adapter, dataloader, device):\n",
    "    \"\"\"Evaluates the model on the provided dataloader.\"\"\"\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Initialize dictionaries to track losses per topic and subtopic\n",
    "    topic_losses = {}\n",
    "    subtopic_losses = {}\n",
    "    topic_counts = {}\n",
    "    subtopic_counts = {}\n",
    "    \n",
    "    with torch.no_grad():  # No gradient calculation during evaluation\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            # Move batch tensors to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            topics = batch['topic']\n",
    "            subtopics = batch['subtopic']\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model_forward_with_mlora(\n",
    "                model=model,\n",
    "                mlora_adapter=mlora_adapter,\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            # Calculate loss (CE only for evaluation)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "            \n",
    "            # Update total loss\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update topic and subtopic losses\n",
    "            for topic, subtopic in zip(topics, subtopics):\n",
    "                # Update topic losses\n",
    "                if topic not in topic_losses:\n",
    "                    topic_losses[topic] = 0.0\n",
    "                    topic_counts[topic] = 0\n",
    "                topic_losses[topic] += loss.item()\n",
    "                topic_counts[topic] += 1\n",
    "                \n",
    "                # Update subtopic losses\n",
    "                if subtopic not in subtopic_losses:\n",
    "                    subtopic_losses[subtopic] = 0.0\n",
    "                    subtopic_counts[subtopic] = 0\n",
    "                subtopic_losses[subtopic] += loss.item()\n",
    "                subtopic_counts[subtopic] += 1\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')\n",
    "    \n",
    "    # Calculate average losses per topic and subtopic\n",
    "    avg_topic_losses = {topic: loss / topic_counts[topic] for topic, loss in topic_losses.items()}\n",
    "    avg_subtopic_losses = {subtopic: loss / subtopic_counts[subtopic] for subtopic, loss in subtopic_losses.items()}\n",
    "    \n",
    "    return avg_loss, avg_topic_losses, avg_subtopic_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f814b315088418c8b417db176545886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): GemmaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777bb517bc2b45b09aafa05417920fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcb76883b0549a4bc3815273f0de8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = load_and_prepare_data(\n",
    "            tokenizer, DATASET_SLICE_TRAIN, DATASET_NAME, DATASET_CONFIG, MAX_SEQ_LENGTH, BATCH_SIZE\n",
    "        )\n",
    "test_dataloader = load_and_prepare_data(\n",
    "            tokenizer, DATASET_SLICE_TEST, DATASET_NAME, DATASET_CONFIG, MAX_SEQ_LENGTH, BATCH_SIZE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervention(mlora, cluster_index, num_clusters=4, style='OFF'):\n",
    "    new_mlora = MLoRAAdapter(\n",
    "        input_dim=mlora.input_dim,\n",
    "        output_dim=mlora.output_dim,\n",
    "        rank=mlora.rank\n",
    "    )\n",
    "    new_mlora.load_state_dict(mlora.state_dict())\n",
    "    B_matrix = new_mlora.B.weight.data  # Shape: [rank, rank]\n",
    "    cluster_size = B_matrix.shape[0] // num_clusters\n",
    "    start_idx = cluster_index * cluster_size\n",
    "    end_idx = (cluster_index + 1) * cluster_size\n",
    "    \n",
    "    if style == 'OFF':\n",
    "        # Original behavior - zero out the specified cluster\n",
    "        B_matrix[start_idx:end_idx, start_idx:end_idx] = 0\n",
    "    else:  # style == 'ON'\n",
    "        # Zero out all clusters except the specified one\n",
    "        for i in range(num_clusters):\n",
    "            curr_start = i * cluster_size\n",
    "            curr_end = (i + 1) * cluster_size\n",
    "            if i != cluster_index:\n",
    "                B_matrix[curr_start:curr_end, curr_start:curr_end] = 0\n",
    "    \n",
    "    return new_mlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlora_adapter_path: str = 'results/mlora_adapter.pt'\n",
    "\n",
    "input_dim = model.config.hidden_size\n",
    "output_dim = model.config.hidden_size\n",
    "safe_rank = min(MLORA_RANK, input_dim, output_dim)  \n",
    "\n",
    "mlora_adapter = MLoRAAdapter(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            rank=safe_rank\n",
    "    )\n",
    "mlora_adapter.load_state_dict(torch.load(mlora_adapter_path))\n",
    "\n",
    "imlora_adapter = intervention(mlora_adapter, cluster_index=0, num_clusters=4, style='OFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imlora_adapter.B.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLoRAAdapter(\n",
       "  (A): Linear(in_features=2048, out_features=256, bias=False)\n",
       "  (B): Linear(in_features=256, out_features=256, bias=False)\n",
       "  (C): Linear(in_features=256, out_features=2048, bias=False)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_handle = register_mlora_hook(model, imlora_adapter, TARGET_LAYER_INDEX)\n",
    "\n",
    "imlora_adapter.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2fe8ace3974ae081f37b478ae976a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss, topic_losses, subtopic_losses = evaluate_model(model, imlora_adapter, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.036648738384248"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Inorganic Chemistry': 9.002590307548864,\n",
       " 'Organic Chemistry': 9.636113495662295,\n",
       " 'Physical Chemistry': 8.45674735446309}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Oxidation States': 9.002590307548864,\n",
       " 'Alkenes': 9.919207445780437,\n",
       " 'Nomenclature': 9.332798549107142,\n",
       " 'Kinetics': 8.45674735446309}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtopic_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_hooks(model):\n",
    "    \"\"\"Remove all hooks from a model and its submodules.\"\"\"\n",
    "    # Remove hooks from each module\n",
    "    for module in model.modules():\n",
    "        module._forward_hooks.clear()\n",
    "        module._forward_pre_hooks.clear()\n",
    "        module._backward_hooks.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating style=ON, cluster_index=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039093679dc34bf2b0a0d31d8b09826a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating style=ON, cluster_index=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2584f8fc538a49f8a7eed9213e6c3538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating style=ON, cluster_index=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7765ca0e8910485abbeab31fd3183a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating style=ON, cluster_index=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3c02336599488e9b637b55020ccf88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating style=OFF, cluster_index=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38acfa36b74e4209a607f591c8657257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating style=OFF, cluster_index=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029929a05b8042c384f847828dc96aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating style=OFF, cluster_index=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b811b0b7854f4792724f88cbd49b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating style=OFF, cluster_index=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d467dfc65045b6b484468e63d34f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_dict = {\n",
    "    'ON': [],\n",
    "    'OFF': []\n",
    "}\n",
    "\n",
    "for style in ['ON', 'OFF']:\n",
    "    for cluster_index in range(4):\n",
    "        print(f\"Evaluating style={style}, cluster_index={cluster_index}\")\n",
    "        remove_all_hooks(model)\n",
    "        imlora_adapter = intervention(\n",
    "            mlora_adapter, \n",
    "            cluster_index=cluster_index, \n",
    "            num_clusters=4, \n",
    "            style=style,\n",
    "            )\n",
    "        imlora_adapter.to(device)\n",
    "        hook_handle = register_mlora_hook(model, imlora_adapter, TARGET_LAYER_INDEX)\n",
    "        test_loss, topic_losses, subtopic_losses = evaluate_model(\n",
    "            model, imlora_adapter, test_dataloader, device\n",
    "        )\n",
    "        results_dict[style].append({\n",
    "            'topic_losses': topic_losses,\n",
    "            'subtopic_losses': subtopic_losses\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ON': [{'topic_losses': {'Inorganic Chemistry': 5.2309326769700695,\n",
       "    'Organic Chemistry': 5.787021308109678,\n",
       "    'Physical Chemistry': 4.535642568455186},\n",
       "   'subtopic_losses': {'Oxidation States': 5.2309326769700695,\n",
       "    'Alkenes': 5.995877891116672,\n",
       "    'Nomenclature': 5.563246397745042,\n",
       "    'Kinetics': 4.535642568455186}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 5.202829268441271,\n",
       "    'Organic Chemistry': 5.756752967834473,\n",
       "    'Physical Chemistry': 4.490657379460889},\n",
       "   'subtopic_losses': {'Oxidation States': 5.202829268441271,\n",
       "    'Alkenes': 5.963387976752387,\n",
       "    'Nomenclature': 5.535358315422421,\n",
       "    'Kinetics': 4.490657379460889}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 5.247637093956791,\n",
       "    'Organic Chemistry': 5.79934916002997,\n",
       "    'Physical Chemistry': 4.5467608085898465},\n",
       "   'subtopic_losses': {'Oxidation States': 5.247637093956791,\n",
       "    'Alkenes': 6.00380441877577,\n",
       "    'Nomenclature': 5.580289954230899,\n",
       "    'Kinetics': 4.5467608085898465}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 5.136533580609222,\n",
       "    'Organic Chemistry': 5.697744457201026,\n",
       "    'Physical Chemistry': 4.434875249862671},\n",
       "   'subtopic_losses': {'Oxidation States': 5.136533580609222,\n",
       "    'Alkenes': 5.90706255171034,\n",
       "    'Nomenclature': 5.47347507022676,\n",
       "    'Kinetics': 4.434875249862671}}],\n",
       " 'OFF': [{'topic_losses': {'Inorganic Chemistry': 4.3396862941001775,\n",
       "    'Organic Chemistry': 4.841219082645987,\n",
       "    'Physical Chemistry': 3.6604949624039405},\n",
       "   'subtopic_losses': {'Oxidation States': 4.3396862941001775,\n",
       "    'Alkenes': 5.034695323308309,\n",
       "    'Nomenclature': 4.633923110507784,\n",
       "    'Kinetics': 3.6604949624039405}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 4.350291277045634,\n",
       "    'Organic Chemistry': 4.854019417159859,\n",
       "    'Physical Chemistry': 3.682583290477132},\n",
       "   'subtopic_losses': {'Oxidation States': 4.350291277045634,\n",
       "    'Alkenes': 5.046385060416328,\n",
       "    'Nomenclature': 4.647913370813642,\n",
       "    'Kinetics': 3.682583290477132}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 4.326246001827183,\n",
       "    'Organic Chemistry': 4.829450925191243,\n",
       "    'Physical Chemistry': 3.6538272597068966},\n",
       "   'subtopic_losses': {'Oxidation States': 4.326246001827183,\n",
       "    'Alkenes': 5.025513055589464,\n",
       "    'Nomenclature': 4.619384356907436,\n",
       "    'Kinetics': 3.6538272597068966}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 4.379129046824441,\n",
       "    'Organic Chemistry': 4.8762514810452515,\n",
       "    'Physical Chemistry': 3.6992800318917562},\n",
       "   'subtopic_losses': {'Oxidation States': 4.379129046824441,\n",
       "    'Alkenes': 5.067869091033936,\n",
       "    'Nomenclature': 4.670946898914519,\n",
       "    'Kinetics': 3.6992800318917562}}]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#1ABC9C"
         },
         "name": "Cluster 0",
         "showlegend": true,
         "type": "bar",
         "x": [
          "Inorganic Chemistry",
          "Organic Chemistry",
          "Physical Chemistry"
         ],
         "xaxis": "x",
         "y": [
          5.231,
          5.787,
          4.536
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#E74C3C"
         },
         "name": "Cluster 1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Inorganic Chemistry",
          "Organic Chemistry",
          "Physical Chemistry"
         ],
         "xaxis": "x",
         "y": [
          5.203,
          5.757,
          4.491
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#3498DB"
         },
         "name": "Cluster 2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Inorganic Chemistry",
          "Organic Chemistry",
          "Physical Chemistry"
         ],
         "xaxis": "x",
         "y": [
          5.248,
          5.799,
          4.547
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#F1C40F"
         },
         "name": "Cluster 3",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Inorganic Chemistry",
          "Organic Chemistry",
          "Physical Chemistry"
         ],
         "xaxis": "x",
         "y": [
          5.137,
          5.698,
          4.435
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#1ABC9C"
         },
         "name": "Cluster 0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Inorganic Chemistry",
          "Organic Chemistry",
          "Physical Chemistry"
         ],
         "xaxis": "x2",
         "y": [
          4.34,
          4.841,
          3.66
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#E74C3C"
         },
         "name": "Cluster 1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Inorganic Chemistry",
          "Organic Chemistry",
          "Physical Chemistry"
         ],
         "xaxis": "x2",
         "y": [
          4.35,
          4.854,
          3.683
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#3498DB"
         },
         "name": "Cluster 2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Inorganic Chemistry",
          "Organic Chemistry",
          "Physical Chemistry"
         ],
         "xaxis": "x2",
         "y": [
          4.326,
          4.829,
          3.654
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#F1C40F"
         },
         "name": "Cluster 3",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Inorganic Chemistry",
          "Organic Chemistry",
          "Physical Chemistry"
         ],
         "xaxis": "x2",
         "y": [
          4.379,
          4.876,
          3.699
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#1ABC9C"
         },
         "name": "Cluster 0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Oxidation States",
          "Alkenes",
          "Nomenclature",
          "Kinetics"
         ],
         "xaxis": "x3",
         "y": [
          5.231,
          5.996,
          5.563,
          4.536
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E74C3C"
         },
         "name": "Cluster 1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Oxidation States",
          "Alkenes",
          "Nomenclature",
          "Kinetics"
         ],
         "xaxis": "x3",
         "y": [
          5.203,
          5.963,
          5.535,
          4.491
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#3498DB"
         },
         "name": "Cluster 2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Oxidation States",
          "Alkenes",
          "Nomenclature",
          "Kinetics"
         ],
         "xaxis": "x3",
         "y": [
          5.248,
          6.004,
          5.58,
          4.547
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#F1C40F"
         },
         "name": "Cluster 3",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Oxidation States",
          "Alkenes",
          "Nomenclature",
          "Kinetics"
         ],
         "xaxis": "x3",
         "y": [
          5.137,
          5.907,
          5.473,
          4.435
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#1ABC9C"
         },
         "name": "Cluster 0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Oxidation States",
          "Alkenes",
          "Nomenclature",
          "Kinetics"
         ],
         "xaxis": "x4",
         "y": [
          4.34,
          5.035,
          4.634,
          3.66
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#E74C3C"
         },
         "name": "Cluster 1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Oxidation States",
          "Alkenes",
          "Nomenclature",
          "Kinetics"
         ],
         "xaxis": "x4",
         "y": [
          4.35,
          5.046,
          4.648,
          3.683
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#3498DB"
         },
         "name": "Cluster 2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Oxidation States",
          "Alkenes",
          "Nomenclature",
          "Kinetics"
         ],
         "xaxis": "x4",
         "y": [
          4.326,
          5.026,
          4.619,
          3.654
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#F1C40F"
         },
         "name": "Cluster 3",
         "showlegend": false,
         "type": "bar",
         "x": [
          "Oxidation States",
          "Alkenes",
          "Nomenclature",
          "Kinetics"
         ],
         "xaxis": "x4",
         "y": [
          4.379,
          5.068,
          4.671,
          3.699
         ],
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "ON - Topics",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "OFF - Topics",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "ON - Subtopics",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.425,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "OFF - Subtopics",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.425,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "barmode": "group",
        "font": {
         "family": "Computer Modern",
         "size": 16
        },
        "height": 800,
        "legend": {
         "font": {
          "size": 16
         },
         "orientation": "h",
         "x": 1,
         "xanchor": "right",
         "y": 1.02,
         "yanchor": "bottom"
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cluster Interventions on MLoRA: ON and OFF"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "gridcolor": "lightgray",
         "tickangle": 45,
         "tickfont": {
          "size": 16
         },
         "zerolinecolor": "lightgray"
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "gridcolor": "lightgray",
         "tickangle": 45,
         "tickfont": {
          "size": 16
         },
         "zerolinecolor": "lightgray"
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ],
         "gridcolor": "lightgray",
         "tickangle": 45,
         "tickfont": {
          "size": 16
         },
         "zerolinecolor": "lightgray"
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ],
         "gridcolor": "lightgray",
         "tickangle": 45,
         "tickfont": {
          "size": 16
         },
         "zerolinecolor": "lightgray"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.575,
          1
         ],
         "gridcolor": "lightgray",
         "tickfont": {
          "size": 16
         },
         "title": {
          "font": {
           "size": 16
          },
          "text": "Loss"
         },
         "zerolinecolor": "lightgray"
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.575,
          1
         ],
         "gridcolor": "lightgray",
         "tickfont": {
          "size": 16
         },
         "title": {
          "font": {
           "size": 16
          },
          "text": "Loss"
         },
         "zerolinecolor": "lightgray"
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.425
         ],
         "gridcolor": "lightgray",
         "tickfont": {
          "size": 16
         },
         "title": {
          "font": {
           "size": 16
          },
          "text": "Loss"
         },
         "zerolinecolor": "lightgray"
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.425
         ],
         "gridcolor": "lightgray",
         "tickfont": {
          "size": 16
         },
         "title": {
          "font": {
           "size": 16
          },
          "text": "Loss"
         },
         "zerolinecolor": "lightgray"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "data = results_dict\n",
    "\n",
    "# Create subplots: 2 rows, 2 columns\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('ON - Topics', 'OFF - Topics', 'ON - Subtopics', 'OFF - Subtopics'),\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# Elegant dark colors\n",
    "colors = ['#1ABC9C', '#E74C3C', '#3498DB', '#F1C40F']\n",
    "\n",
    "# Plot ON Topics (top left)\n",
    "for i, cluster_data in enumerate(data['ON']):\n",
    "    topics = list(cluster_data['topic_losses'].keys())\n",
    "    values = [round(val, 3) for val in cluster_data['topic_losses'].values()]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=topics,\n",
    "            y=values,\n",
    "            name=f'Cluster {i}',\n",
    "            marker_color=colors[i],\n",
    "            showlegend=(i == 0)  # Only show legend for first set\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Plot OFF Topics (top right)\n",
    "for i, cluster_data in enumerate(data['OFF']):\n",
    "    topics = list(cluster_data['topic_losses'].keys())\n",
    "    values = [round(val, 3) for val in cluster_data['topic_losses'].values()]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=topics,\n",
    "            y=values,\n",
    "            name=f'Cluster {i}',\n",
    "            marker_color=colors[i],\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Plot ON Subtopics (bottom left)\n",
    "for i, cluster_data in enumerate(data['ON']):\n",
    "    subtopics = list(cluster_data['subtopic_losses'].keys())\n",
    "    values = [round(val, 3) for val in cluster_data['subtopic_losses'].values()]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=subtopics,\n",
    "            y=values,\n",
    "            name=f'Cluster {i}',\n",
    "            marker_color=colors[i],\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Plot OFF Subtopics (bottom right)\n",
    "for i, cluster_data in enumerate(data['OFF']):\n",
    "    subtopics = list(cluster_data['subtopic_losses'].keys())\n",
    "    values = [round(val, 3) for val in cluster_data['subtopic_losses'].values()]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=subtopics,\n",
    "            y=values,\n",
    "            name=f'Cluster {i}',\n",
    "            marker_color=colors[i],\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Cluster Interventions on MLoRA: ON and OFF',\n",
    "    height=800,\n",
    "    width=1200,\n",
    "    barmode='group',\n",
    "    font=dict(\n",
    "        family=\"Computer Modern\",\n",
    "        size=16\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white',\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1,\n",
    "        font=dict(size=16)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update y-axes labels\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Loss\",\n",
    "    row=1, col=1,\n",
    "    gridcolor='lightgray',\n",
    "    zerolinecolor='lightgray',\n",
    "    title_font=dict(size=16),\n",
    "    tickfont=dict(size=16)\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Loss\",\n",
    "    row=1, col=2,\n",
    "    gridcolor='lightgray',\n",
    "    zerolinecolor='lightgray',\n",
    "    title_font=dict(size=16),\n",
    "    tickfont=dict(size=16)\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Loss\",\n",
    "    row=2, col=1,\n",
    "    gridcolor='lightgray',\n",
    "    zerolinecolor='lightgray',\n",
    "    title_font=dict(size=16),\n",
    "    tickfont=dict(size=16)\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Loss\",\n",
    "    row=2, col=2,\n",
    "    gridcolor='lightgray',\n",
    "    zerolinecolor='lightgray',\n",
    "    title_font=dict(size=16),\n",
    "    tickfont=dict(size=16)\n",
    ")\n",
    "\n",
    "# Update x-axes\n",
    "for i in range(1, 3):\n",
    "    for j in range(1, 3):\n",
    "        fig.update_xaxes(\n",
    "            tickangle=45,\n",
    "            gridcolor='lightgray',\n",
    "            zerolinecolor='lightgray',\n",
    "            row=i, col=j,\n",
    "            tickfont=dict(size=16)\n",
    "        )\n",
    "\n",
    "# Update subplot titles\n",
    "fig.update_annotations(font_size=16)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ON': [{'topic_losses': {'Inorganic Chemistry': 5.2309326769700695,\n",
       "    'Organic Chemistry': 5.787021308109678,\n",
       "    'Physical Chemistry': 4.535642568455186},\n",
       "   'subtopic_losses': {'Oxidation States': 5.2309326769700695,\n",
       "    'Alkenes': 5.995877891116672,\n",
       "    'Nomenclature': 5.563246397745042,\n",
       "    'Kinetics': 4.535642568455186}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 5.202829268441271,\n",
       "    'Organic Chemistry': 5.756752967834473,\n",
       "    'Physical Chemistry': 4.490657379460889},\n",
       "   'subtopic_losses': {'Oxidation States': 5.202829268441271,\n",
       "    'Alkenes': 5.963387976752387,\n",
       "    'Nomenclature': 5.535358315422421,\n",
       "    'Kinetics': 4.490657379460889}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 5.247637093956791,\n",
       "    'Organic Chemistry': 5.79934916002997,\n",
       "    'Physical Chemistry': 4.5467608085898465},\n",
       "   'subtopic_losses': {'Oxidation States': 5.247637093956791,\n",
       "    'Alkenes': 6.00380441877577,\n",
       "    'Nomenclature': 5.580289954230899,\n",
       "    'Kinetics': 4.5467608085898465}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 5.136533580609222,\n",
       "    'Organic Chemistry': 5.697744457201026,\n",
       "    'Physical Chemistry': 4.434875249862671},\n",
       "   'subtopic_losses': {'Oxidation States': 5.136533580609222,\n",
       "    'Alkenes': 5.90706255171034,\n",
       "    'Nomenclature': 5.47347507022676,\n",
       "    'Kinetics': 4.434875249862671}}],\n",
       " 'OFF': [{'topic_losses': {'Inorganic Chemistry': 4.3396862941001775,\n",
       "    'Organic Chemistry': 4.841219082645987,\n",
       "    'Physical Chemistry': 3.6604949624039405},\n",
       "   'subtopic_losses': {'Oxidation States': 4.3396862941001775,\n",
       "    'Alkenes': 5.034695323308309,\n",
       "    'Nomenclature': 4.633923110507784,\n",
       "    'Kinetics': 3.6604949624039405}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 4.350291277045634,\n",
       "    'Organic Chemistry': 4.854019417159859,\n",
       "    'Physical Chemistry': 3.682583290477132},\n",
       "   'subtopic_losses': {'Oxidation States': 4.350291277045634,\n",
       "    'Alkenes': 5.046385060416328,\n",
       "    'Nomenclature': 4.647913370813642,\n",
       "    'Kinetics': 3.682583290477132}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 4.326246001827183,\n",
       "    'Organic Chemistry': 4.829450925191243,\n",
       "    'Physical Chemistry': 3.6538272597068966},\n",
       "   'subtopic_losses': {'Oxidation States': 4.326246001827183,\n",
       "    'Alkenes': 5.025513055589464,\n",
       "    'Nomenclature': 4.619384356907436,\n",
       "    'Kinetics': 3.6538272597068966}},\n",
       "  {'topic_losses': {'Inorganic Chemistry': 4.379129046824441,\n",
       "    'Organic Chemistry': 4.8762514810452515,\n",
       "    'Physical Chemistry': 3.6992800318917562},\n",
       "   'subtopic_losses': {'Oxidation States': 4.379129046824441,\n",
       "    'Alkenes': 5.067869091033936,\n",
       "    'Nomenclature': 4.670946898914519,\n",
       "    'Kinetics': 3.6992800318917562}}]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/interventions_results_chemistry.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
